{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T10:38:51.484923Z",
     "start_time": "2024-11-03T10:38:51.481419Z"
    }
   },
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T10:38:51.694578Z",
     "start_time": "2024-11-03T10:38:51.676248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_pipeline(classifier):\n",
    "  categorical_features = [\n",
    "      'sex',\n",
    "      'chest-pain',\n",
    "      'fasting-blood-sugar',\n",
    "      'electrocardiographic',\n",
    "      'angina',\n",
    "      'thal'\n",
    "  ]\n",
    "  numerical_features = [\n",
    "      'age',\n",
    "      'rest-bp',\n",
    "      'serum-chol',\n",
    "      'max-heart-rate',\n",
    "      'oldpeak',\n",
    "      'slope',\n",
    "      'major-vessels',\n",
    "  ]\n",
    "  column_transformer = ColumnTransformer(transformers=[\n",
    "      ('ohe', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "      ('scaling', StandardScaler(), numerical_features)\n",
    "  ])\n",
    "  pipeline = Pipeline(steps=[\n",
    "      ('transform', column_transformer),\n",
    "      ('classifier', classifier)\n",
    "  ])\n",
    "  return pipeline\n",
    "\n",
    "\n",
    "def get_cross_val_predictions(X, y, pipeline, n_splits, random_state):\n",
    "  cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "  result = np.zeros((X.shape[0],))\n",
    "  for train_index, test_index in cv.split(X, y):\n",
    "    X_train = X.iloc[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    result[test_index] = pipeline.predict(X_test)\n",
    "  return result\n",
    "\n",
    "\n",
    "def get_perf_metrics(y_true, y_pred):\n",
    "  y_true_switched = (y_true + 1) % 2\n",
    "  y_pred_switched = (y_pred + 1) % 2\n",
    "\n",
    "  precision0 = metrics.precision_score(y_true, y_pred, pos_label=0, zero_division=0.0)\n",
    "  recall0 = metrics.recall_score(y_true, y_pred, pos_label=0, zero_division=0.0)\n",
    "  precision1 = metrics.precision_score(y_true, y_pred, pos_label=1, zero_division=0.0)\n",
    "  recall1 =  metrics.recall_score(y_true, y_pred, pos_label=1, zero_division=0.0)\n",
    "\n",
    "  f1_score0 = metrics.f1_score(y_true, y_pred, pos_label=0, zero_division=0.0)\n",
    "  f1_score1 = metrics.f1_score(y_true, y_pred, pos_label=1, zero_division=0.0)\n",
    "\n",
    "  accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "  jaccard_index = np.sum(y_true == y_pred) / (len(y_true) + len(y_pred) - np.sum(y_true == y_pred))\n",
    "\n",
    "  return {\n",
    "      'accuracy': accuracy,\n",
    "      'precision0': precision0,\n",
    "      'recall0': recall0,\n",
    "      'precision1': precision1,\n",
    "      'recall1': recall1,\n",
    "      'balanced_accuracy': (recall0 + recall1) / 2,\n",
    "      'f1_score0': f1_score0,\n",
    "      'f1_score1': f1_score1,\n",
    "      'average_f1_score': (f1_score0 + f1_score1) / 2,\n",
    "      'fowlkes_mallows0': np.sqrt(precision0 * recall0),\n",
    "      'fowlkes_mallows1': np.sqrt(precision1 * recall1),\n",
    "      'markedness': precision0 + precision1 - 1,\n",
    "      'mcc': metrics.matthews_corrcoef(y_true, y_pred),\n",
    "      'jaccard_index': jaccard_index,\n",
    "      'cohens_kappa': metrics.cohen_kappa_score(y_true, y_pred)\n",
    "  }\n",
    "\n",
    "\n",
    "def validate_models(models, X, y, n_splits, random_state, log=False, log_names=None, fake_models=None):\n",
    "  perf_metrics_list = []\n",
    "  if log:\n",
    "    iterable = tqdm(models)\n",
    "  else:\n",
    "    iterable = models\n",
    "  for i, model in enumerate(iterable):\n",
    "    if log and log_names is not None:\n",
    "      iterable.set_description(log_names[i])\n",
    "    pipeline = get_pipeline(model)\n",
    "    y_pred = get_cross_val_predictions(X, y, pipeline, n_splits, random_state)\n",
    "    perf_metrics = get_perf_metrics(y, y_pred)\n",
    "    perf_metrics_list.append(perf_metrics)\n",
    "\n",
    "  if fake_models is not None:\n",
    "    for y_pred in fake_models:\n",
    "      perf_metrics_list.append(get_perf_metrics(y, y_pred))\n",
    "\n",
    "\n",
    "  return pd.DataFrame.from_records(perf_metrics_list)\n",
    "\n",
    "\n",
    "class ThresholdedModel(BaseEstimator):\n",
    "  def __init__(self, model, threshold):\n",
    "    self.model = model\n",
    "    self.threshold = threshold\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    self.model.fit(X, y)\n",
    "\n",
    "  def predict(self, X):\n",
    "    proba_predictions = self.model.predict_proba(X)[:, 1]\n",
    "    return np.where(proba_predictions > self.threshold, 1, 0)\n",
    "\n",
    "def get_performance_metrics(random_state=42):\n",
    "    stdf = pd.read_csv('datasets/statlog_heart.csv')\n",
    "    y = stdf['target']\n",
    "    X = stdf.drop(columns=['target'])\n",
    "    \n",
    "    models = []\n",
    "    names = []\n",
    "    \n",
    "    threshold_range = [0.2, 0.5, 0.8]\n",
    "    \n",
    "    def add_model(name, model):\n",
    "        names.append(name)\n",
    "        models.append(model)\n",
    "        \n",
    "    for max_depth in [1, 2, 4, 8, None]:\n",
    "      add_model(\n",
    "          f'DecisionTreeClassifier(max_depth={max_depth})',\n",
    "          DecisionTreeClassifier(max_depth=max_depth, random_state=random_state)\n",
    "      )\n",
    "    add_model(\n",
    "        'BernoulliNB',\n",
    "        BernoulliNB()\n",
    "    )\n",
    "    for threshold in threshold_range:\n",
    "      for hidden_layer_sizes in [\n",
    "          (1,),\n",
    "          (10,),\n",
    "          (100,),\n",
    "          (200,),\n",
    "          (10, 10),\n",
    "      ]:\n",
    "        add_model(\n",
    "            f'MLPClassifier(sizes={hidden_layer_sizes}), thr={threshold}',\n",
    "            ThresholdedModel(MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=1000, early_stopping=True, n_iter_no_change=100, random_state=random_state), threshold)\n",
    "        )\n",
    "    \n",
    "    for k in [1, 2, 3, 5, 7, 9]:\n",
    "      add_model(\n",
    "          f'KNeighborsClassifier(k={k})',\n",
    "          KNeighborsClassifier(n_neighbors=k)\n",
    "      )\n",
    "    \n",
    "    for threshold in threshold_range:\n",
    "      for C in [0.01, 0.1, 1, 2, 4, 8]:\n",
    "        add_model(\n",
    "            f'LinearSVC(C={C}), thr={threshold}',\n",
    "            ThresholdedModel(SVC(kernel='linear', C=C, probability=True, random_state=random_state), threshold)\n",
    "        )\n",
    "    \n",
    "    for threshold in threshold_range:\n",
    "      for degree in [2, 3, 4]:\n",
    "        for gamma in [0.001, 0.01, 0.1]:\n",
    "          add_model(\n",
    "              f'PolySVC(degree={degree}, gamma={gamma}), thr={threshold}',\n",
    "              ThresholdedModel(SVC(kernel='poly', degree=degree, gamma=gamma, probability=True, random_state=random_state), threshold)\n",
    "          )\n",
    "    \n",
    "    for threshold in threshold_range:\n",
    "      for C in [0.01, 0.1, 1, 2, 4, 8]:\n",
    "        add_model(\n",
    "            f'RBFSVM(C={C}), thr={threshold}',\n",
    "            ThresholdedModel(SVC(kernel='rbf', C=C, probability=True, random_state=random_state), threshold)\n",
    "        )\n",
    "    \n",
    "    for threshold in threshold_range:\n",
    "      for max_depth in [2, 8, None]:\n",
    "        for n_estimators in [8, 32, 128]:\n",
    "          add_model(\n",
    "              f'RF(max_depth={max_depth}, n={n_estimators}), thr={threshold}',\n",
    "              ThresholdedModel(RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state), threshold)\n",
    "          )\n",
    "    \n",
    "    for threshold in threshold_range:\n",
    "      for num_leaves in [4, 8, 32]:\n",
    "        for n_estimators in [8, 32, 128]:\n",
    "          add_model(\n",
    "              f'LGBM(num_leaves={num_leaves}, n={n_estimators}), thr={threshold}',\n",
    "              ThresholdedModel(lgb.LGBMClassifier(num_leaves=num_leaves, n_estimators=n_estimators, verbosity=-1, random_state=random_state), threshold)\n",
    "          )\n",
    "    \n",
    "    fake_models = []\n",
    "    \n",
    "    names.append('OptimalClassifier')\n",
    "    fake_models.append(y)\n",
    "    names.append('PessimalClassifier')\n",
    "    fake_models.append((y + 1) % 2)\n",
    "    \n",
    "    counts = np.bincount(y)\n",
    "    y_majority_el = np.argmax(counts)\n",
    "    y_majority = np.full(y.shape, y_majority_el)\n",
    "    \n",
    "    names.append('MajorityClassifier')\n",
    "    fake_models.append(y_majority)\n",
    "    names.append('MinorityClassifier')\n",
    "    fake_models.append((y_majority + 1) % 2)\n",
    "    names.append('RandomClassifier')\n",
    "    np.random.seed(random_state)\n",
    "    fake_models.append(np.random.binomial(n=1, p=0.5, size=y.shape))\n",
    "    \n",
    "    df = validate_models(\n",
    "        models=models,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        n_splits=10,\n",
    "        random_state=random_state,\n",
    "        log=True,\n",
    "        log_names=names,\n",
    "        fake_models=fake_models\n",
    "    )\n",
    "    \n",
    "    df.insert(0, column='name', value=names)\n",
    "    \n",
    "    df['markedness'] = (df['markedness'] + 1) / 2\n",
    "    df['mcc'] = (df['mcc'] + 1) / 2\n",
    "    df['cohens_kappa'] = (df['cohens_kappa'] + 1) / 2\n",
    "    \n",
    "    return df"
   ],
   "id": "23ff2b73d495a87b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T10:40:01.086736Z",
     "start_time": "2024-11-03T10:38:55.471362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = get_performance_metrics(random_state=42)\n",
    "df.to_csv('results/performance_metrics.csv', index=False)"
   ],
   "id": "e25fd466464493d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70ab8f7f39034a4d8dccedf6eeb54071"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
